{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# defaultcit\n",
    "from collections import defaultdict\n",
    "\n",
    "# plot with folium\n",
    "import folium\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# parsing time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# plotting with matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "# plotting with pylab\n",
    "import pylab as P\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "import time\n",
    "import json\n",
    "\n",
    "# change prediction categories into labels\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_validation \n",
    "from sklearn import svm\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Training/Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** subset to only the fields we need and used in submission (Dates, DayOfWeek, PdDistrict, Address, X, Y, Category) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "# train_df = train_df.sample(n = 100000, random_state = 666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>WARRANTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-13 23:33:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>VANNESS AV / GREENWICH ST</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800414</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>1500 Block of LOMBARD ST</td>\n",
       "      <td>-122.426995</td>\n",
       "      <td>37.800873</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>PARK</td>\n",
       "      <td>100 Block of BRODERICK ST</td>\n",
       "      <td>-122.438738</td>\n",
       "      <td>37.771541</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dates  DayOfWeek PdDistrict                    Address  \\\n",
       "0  2015-05-13 23:53:00  Wednesday   NORTHERN         OAK ST / LAGUNA ST   \n",
       "1  2015-05-13 23:53:00  Wednesday   NORTHERN         OAK ST / LAGUNA ST   \n",
       "2  2015-05-13 23:33:00  Wednesday   NORTHERN  VANNESS AV / GREENWICH ST   \n",
       "3  2015-05-13 23:30:00  Wednesday   NORTHERN   1500 Block of LOMBARD ST   \n",
       "4  2015-05-13 23:30:00  Wednesday       PARK  100 Block of BRODERICK ST   \n",
       "\n",
       "            X          Y        Category  \n",
       "0 -122.425892  37.774599        WARRANTS  \n",
       "1 -122.425892  37.774599  OTHER OFFENSES  \n",
       "2 -122.424363  37.800414  OTHER OFFENSES  \n",
       "3 -122.426995  37.800873   LARCENY/THEFT  \n",
       "4 -122.438738  37.771541   LARCENY/THEFT  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(train_df)\n",
    "test_df = pd.DataFrame(test_df)\n",
    "# train_df = train_df.reset_index(drop=True)\n",
    "train_df = train_df[['Dates','DayOfWeek','PdDistrict','Address','X','Y','Category']]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dates</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-10 23:59:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>2000 Block of THOMAS AV</td>\n",
       "      <td>-122.399588</td>\n",
       "      <td>37.735051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-10 23:51:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>3RD ST / REVERE AV</td>\n",
       "      <td>-122.391523</td>\n",
       "      <td>37.732432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-10 23:50:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>2000 Block of GOUGH ST</td>\n",
       "      <td>-122.426002</td>\n",
       "      <td>37.792212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-05-10 23:45:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>4700 Block of MISSION ST</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-05-10 23:45:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>4700 Block of MISSION ST</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                Dates DayOfWeek PdDistrict                   Address  \\\n",
       "0   0  2015-05-10 23:59:00    Sunday    BAYVIEW   2000 Block of THOMAS AV   \n",
       "1   1  2015-05-10 23:51:00    Sunday    BAYVIEW        3RD ST / REVERE AV   \n",
       "2   2  2015-05-10 23:50:00    Sunday   NORTHERN    2000 Block of GOUGH ST   \n",
       "3   3  2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n",
       "4   4  2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n",
       "\n",
       "            X          Y  \n",
       "0 -122.399588  37.735051  \n",
       "1 -122.391523  37.732432  \n",
       "2 -122.426002  37.792212  \n",
       "3 -122.437394  37.721412  \n",
       "4 -122.437394  37.721412  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878049, 7)\n",
      "(884262, 7)\n"
     ]
    }
   ],
   "source": [
    "#Look at the shape\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** create feature for training data and also for test data **\n",
    "\n",
    "** difference btw train/test is that training has category data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check\n",
      "(878049, 14)\n",
      "(878049, 2)\n",
      "(878049, 4)\n",
      "(878049, 4)\n",
      "(878049, 10)\n",
      "(878049, 7)\n",
      "(878049, 3)\n",
      "(878049, 44)\n",
      "Make sure the total adds up to the last number\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Category</th>\n",
       "      <th>month_of_year</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>min_of_hour</th>\n",
       "      <th>...</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Corner</th>\n",
       "      <th>Other</th>\n",
       "      <th>Street</th>\n",
       "      <th>dummy_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-13 23:33:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800414</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>-122.426995</td>\n",
       "      <td>37.800873</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>PARK</td>\n",
       "      <td>-122.438738</td>\n",
       "      <td>37.771541</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dates  DayOfWeek PdDistrict           X          Y  \\\n",
       "0  2015-05-13 23:53:00  Wednesday   NORTHERN -122.425892  37.774599   \n",
       "1  2015-05-13 23:53:00  Wednesday   NORTHERN -122.425892  37.774599   \n",
       "2  2015-05-13 23:33:00  Wednesday   NORTHERN -122.424363  37.800414   \n",
       "3  2015-05-13 23:30:00  Wednesday   NORTHERN -122.426995  37.800873   \n",
       "4  2015-05-13 23:30:00  Wednesday       PARK -122.438738  37.771541   \n",
       "\n",
       "         Category  month_of_year  day_of_month  hour_of_day  min_of_hour  \\\n",
       "0        WARRANTS              5            13           23           53   \n",
       "1  OTHER OFFENSES              5            13           23           53   \n",
       "2  OTHER OFFENSES              5            13           23           33   \n",
       "3   LARCENY/THEFT              5            13           23           30   \n",
       "4   LARCENY/THEFT              5            13           23           30   \n",
       "\n",
       "        ...       Monday Saturday Sunday Thursday  Tuesday  Wednesday  Corner  \\\n",
       "0       ...            0        0      0        0        0          1       1   \n",
       "1       ...            0        0      0        0        0          1       1   \n",
       "2       ...            0        0      0        0        0          1       1   \n",
       "3       ...            0        0      0        0        0          1       1   \n",
       "4       ...            0        0      0        0        0          1       0   \n",
       "\n",
       "   Other  Street  dummy_Category  \n",
       "0      0       0              37  \n",
       "1      0       0              21  \n",
       "2      0       0              21  \n",
       "3      0       0              16  \n",
       "4      1       0              16  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def createFeature(train_df):\n",
    "    #Getting Month of Year, Day of Month, Hour of Day, and Minute of Hour\n",
    "    month_of_year = []\n",
    "    day_of_month =[]\n",
    "    hour_of_day =[]\n",
    "    min_of_hour =[]\n",
    "    for i in range(len(train_df.Dates.values)):\n",
    "        moy = datetime.strptime(train_df.Dates.values[i], \"%Y-%m-%d %H:%M:%S\").month\n",
    "        dom = datetime.strptime(train_df.Dates.values[i], \"%Y-%m-%d %H:%M:%S\").day\n",
    "        hod = datetime.strptime(train_df.Dates.values[i], \"%Y-%m-%d %H:%M:%S\").hour\n",
    "        moh = datetime.strptime(train_df.Dates.values[i], \"%Y-%m-%d %H:%M:%S\").minute\n",
    "        month_of_year.append(moy)\n",
    "        day_of_month.append(dom)\n",
    "        hour_of_day.append(hod)\n",
    "        min_of_hour.append(moh)\n",
    "    train_df['month_of_year'] = month_of_year #Month of the Year feature added\n",
    "    train_df['day_of_month'] = day_of_month # Day of Month feature added\n",
    "    train_df['hour_of_day'] = hour_of_day # Hour of Day feature added\n",
    "    train_df['min_of_hour'] = min_of_hour # Minute of Hour Feature added\n",
    "    \n",
    "    #Creating Weeekday/Weekended Feature\n",
    "    train_df['WeekdayWeeekend'] = train_df['DayOfWeek'].map( {'Monday': 'Weekday', 'Tuesday': 'Weekday', \\\n",
    "                                                          'Wednesday': 'Weekday', 'Thursday': 'Weekday', 'Friday': 'Weekend',\\\n",
    "                                                         'Saturday': 'Weekend', 'Sunday': 'Weekday'} ).astype(object)\n",
    "    # Creating Midnight/Morning/Afternoon/Night Column\n",
    "    train_df['TimeOfDay'] = train_df['hour_of_day'].map({0: 'Midnight', 1: 'Midnight', 2:'Midnight', 3:'Midnight', 4:'Morning', \\\n",
    "                                                     5:'Morning', 6:'Morning', 7:'Morning', 8:'Morning', 9:'Morning', \\\n",
    "                                                     10:'Morning', 11:'Morning', 12:'Afternoon', 13:'Afternoon', 14:'Afternoon', \\\n",
    "                                                     15:'Afternoon', 16:'Afternoon', 17:'Afternoon', 18:'Night', 19:'Night', \\\n",
    "                                                     20:'Night', 21:'Night', 22:'Midnight', 23:'Midnight'}).astype(object)\n",
    "    # Creating Season Feature\n",
    "    train_df['Season'] = train_df['month_of_year'].map({1: 'Winter', 2: 'Winter', 3:'Spring', 4:'Spring', 5:'Spring', \\\n",
    "                                                     6:'Spring', 7:'Summer', 8:'Summer', 9:'Summer', 10:'Autumn', \\\n",
    "                                                     11:'Autumn', 12:'Winter'}).astype(object)\n",
    "\n",
    "    \n",
    "    train_df['District_Type'] = train_df['PdDistrict'].map({'PARK': 'Other', 'CENTRAL': 'Other', 'MISSION': 'Corner', 'NORTHERN': 'Corner', \n",
    "                                                              'TENDERLOIN': 'Other', 'INGLESIDE': 'Street', 'TARAVAL': 'Street', \n",
    "                                                              'SOUTHERN': 'Other', 'BAYVIEW': 'Other', 'RICHMOND': 'Other'}).astype(object)\n",
    "\n",
    "        \n",
    "    #Deleting features not needed\n",
    "#     train_df = train_df.drop('Descript', 1)\n",
    "#     train_df = train_df.drop('Resolution', 1)\n",
    "    train_df = train_df.drop('Address', 1)\n",
    "    \n",
    "    #Creating Dummy Variables\n",
    "    WeekdayWeekend_dummies = pd.get_dummies(train_df.WeekdayWeeekend)\n",
    "    TimeOfDay_dummies = pd.get_dummies(train_df.TimeOfDay)\n",
    "    season_dummies = pd.get_dummies(train_df.Season)\n",
    "    district_dummies = pd.get_dummies(train_df.PdDistrict)\n",
    "    week_dummies = pd.get_dummies(train_df.DayOfWeek)\n",
    "#     type_dummies = pd.get_dummies(train_df.Crime_Type)\n",
    "    corner_dummies = pd.get_dummies(train_df.District_Type)\n",
    "    \n",
    "    train_df_new = pd.concat([train_df, WeekdayWeekend_dummies, TimeOfDay_dummies, season_dummies, district_dummies, week_dummies, corner_dummies], axis=1, join_axes=[train_df.index])\n",
    "    print('Sanity Check')\n",
    "    print(train_df.shape)\n",
    "    print(WeekdayWeekend_dummies.shape)\n",
    "    print(TimeOfDay_dummies.shape)\n",
    "    print(season_dummies.shape)\n",
    "    print(district_dummies.shape)\n",
    "    print(week_dummies.shape)\n",
    "#     print(type_dummies.shape)\n",
    "    print(corner_dummies.shape)\n",
    "    print(train_df_new.shape)\n",
    "    print('Make sure the total adds up to the last number')\n",
    "    \n",
    "    le_crime = preprocessing.LabelEncoder()\n",
    "    crime = le_crime.fit_transform(train_df_new.Category)\n",
    "    train_df_new['dummy_Category'] = crime\n",
    "\n",
    "    return train_df_new\n",
    "#Calling the feature creation function\n",
    "train_df_new = createFeature(train_df)\n",
    "train_df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** create feature for test data **\n",
    "\n",
    "*difference is that Cateogry doesn't exist in test data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check\n",
      "(884262, 14)\n",
      "(884262, 2)\n",
      "(884262, 4)\n",
      "(884262, 4)\n",
      "(884262, 10)\n",
      "(884262, 7)\n",
      "(884262, 3)\n",
      "(884262, 44)\n",
      "Make sure the total adds up to the last number\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dates</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>month_of_year</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>min_of_hour</th>\n",
       "      <th>...</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Corner</th>\n",
       "      <th>Other</th>\n",
       "      <th>Street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-10 23:59:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>-122.399588</td>\n",
       "      <td>37.735051</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-10 23:51:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>-122.391523</td>\n",
       "      <td>37.732432</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-10 23:50:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>-122.426002</td>\n",
       "      <td>37.792212</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-05-10 23:45:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-05-10 23:45:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                Dates DayOfWeek PdDistrict           X          Y  \\\n",
       "0   0  2015-05-10 23:59:00    Sunday    BAYVIEW -122.399588  37.735051   \n",
       "1   1  2015-05-10 23:51:00    Sunday    BAYVIEW -122.391523  37.732432   \n",
       "2   2  2015-05-10 23:50:00    Sunday   NORTHERN -122.426002  37.792212   \n",
       "3   3  2015-05-10 23:45:00    Sunday  INGLESIDE -122.437394  37.721412   \n",
       "4   4  2015-05-10 23:45:00    Sunday  INGLESIDE -122.437394  37.721412   \n",
       "\n",
       "   month_of_year  day_of_month  hour_of_day  min_of_hour   ...   Friday  \\\n",
       "0              5            10           23           59   ...        0   \n",
       "1              5            10           23           51   ...        0   \n",
       "2              5            10           23           50   ...        0   \n",
       "3              5            10           23           45   ...        0   \n",
       "4              5            10           23           45   ...        0   \n",
       "\n",
       "  Monday Saturday Sunday  Thursday  Tuesday  Wednesday  Corner  Other  Street  \n",
       "0      0        0      1         0        0          0       0      1       0  \n",
       "1      0        0      1         0        0          0       0      1       0  \n",
       "2      0        0      1         0        0          0       1      0       0  \n",
       "3      0        0      1         0        0          0       0      0       1  \n",
       "4      0        0      1         0        0          0       0      0       1  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_createFeature(test_df):\n",
    "    #Getting Month of Year, Day of Month, Hour of Day, and Minute of Hour\n",
    "    month_of_year = []\n",
    "    day_of_month =[]\n",
    "    hour_of_day =[]\n",
    "    min_of_hour =[]\n",
    "    for i in range(len(test_df.Dates.values)):\n",
    "        moy = datetime.strptime(test_df.Dates.values[i], \"%Y-%m-%d %H:%M:%S\").month\n",
    "        dom = datetime.strptime(test_df.Dates.values[i], \"%Y-%m-%d %H:%M:%S\").day\n",
    "        hod = datetime.strptime(test_df.Dates.values[i], \"%Y-%m-%d %H:%M:%S\").hour\n",
    "        moh = datetime.strptime(test_df.Dates.values[i], \"%Y-%m-%d %H:%M:%S\").minute\n",
    "        month_of_year.append(moy)\n",
    "        day_of_month.append(dom)\n",
    "        hour_of_day.append(hod)\n",
    "        min_of_hour.append(moh)\n",
    "    test_df['month_of_year'] = month_of_year #Month of the Year feature added\n",
    "    test_df['day_of_month'] = day_of_month # Day of Month feature added\n",
    "    test_df['hour_of_day'] = hour_of_day # Hour of Day feature added\n",
    "    test_df['min_of_hour'] = min_of_hour # Minute of Hour Feature added\n",
    "    \n",
    "    #Creating Weeekday/Weekended Feature\n",
    "    test_df['WeekdayWeeekend'] = test_df['DayOfWeek'].map( {'Monday': 'Weekday', 'Tuesday': 'Weekday', \\\n",
    "                                                          'Wednesday': 'Weekend', 'Thursday': 'Weekend', 'Friday': 'Weekend',\\\n",
    "                                                         'Saturday': 'Weekend', 'Sunday': 'Weekday'} ).astype(object)\n",
    "    # Creating Midnight/Morning/Afternoon/Night Column\n",
    "    test_df['TimeOfDay'] = test_df['hour_of_day'].map({0: 'Night', 1: 'Midnight', 2:'Midnight', 3:'Midnight', 4:'Midnight', \\\n",
    "                                                     5:'Midnight', 6:'Midnight', 7:'Midnight', 8:'Morning', 9:'Morning', \\\n",
    "                                                     10:'Morning', 11:'Morning', 12:'Afternoon', 13:'Afternoon', 14:'Afternoon', \\\n",
    "                                                     15:'Afternoon', 16:'Afternoon', 17:'Afternoon', 18:'Afternoon', 19:'Afternoon', \\\n",
    "                                                     20:'Night', 21:'Night', 22:'Night', 23:'Night'}).astype(object)\n",
    "    # Creating Season Feature\n",
    "    test_df['Season'] = test_df['month_of_year'].map({1: 'Winter', 2: 'Winter', 3:'Spring', 4:'Spring', 5:'Spring', \\\n",
    "                                                     6:'Spring', 7:'Summer', 8:'Summer', 9:'Summer', 10:'Autumn', \\\n",
    "                                                     11:'Autumn', 12:'Winter'}).astype(object)\n",
    "\n",
    "    \n",
    "    \n",
    "    test_df['District_Type'] = test_df['PdDistrict'].map({'PARK': 'Other', 'CENTRAL': 'Other', 'MISSION': 'Corner', 'NORTHERN': 'Corner', \n",
    "                                                              'TENDERLOIN': 'Other', 'INGLESIDE': 'Street', 'TARAVAL': 'Street', \n",
    "                                                              'SOUTHERN': 'Other', 'BAYVIEW': 'Other', 'RICHMOND': 'Other'}).astype(object)\n",
    "\n",
    "        \n",
    "    #Deleting features not needed\n",
    "#     test_df = test_df.drop('Descript', 1)\n",
    "#     test_df = test_df.drop('Resolution', 1)\n",
    "    test_df = test_df.drop('Address', 1)\n",
    "    \n",
    "    #Creating Dummy Variables\n",
    "    WeekdayWeekend_dummies = pd.get_dummies(test_df.WeekdayWeeekend)\n",
    "    TimeOfDay_dummies = pd.get_dummies(test_df.TimeOfDay)\n",
    "    season_dummies = pd.get_dummies(test_df.Season)\n",
    "    district_dummies = pd.get_dummies(test_df.PdDistrict)\n",
    "    week_dummies = pd.get_dummies(test_df.DayOfWeek)\n",
    "#     type_dummies = pd.get_dummies(test_df.Crime_Type)\n",
    "    corner_dummies = pd.get_dummies(test_df.District_Type)\n",
    "    \n",
    "    test_df_new = pd.concat([test_df, WeekdayWeekend_dummies, TimeOfDay_dummies, season_dummies, district_dummies, week_dummies, corner_dummies], axis=1, join_axes=[test_df.index])\n",
    "    print('Sanity Check')\n",
    "    print(test_df.shape)\n",
    "    print(WeekdayWeekend_dummies.shape)\n",
    "    print(TimeOfDay_dummies.shape)\n",
    "    print(season_dummies.shape)\n",
    "    print(district_dummies.shape)\n",
    "    print(week_dummies.shape)\n",
    "#     print(type_dummies.shape)\n",
    "    print(corner_dummies.shape)\n",
    "    print(test_df_new.shape)\n",
    "    print('Make sure the total adds up to the last number')\n",
    "    \n",
    "#     le_crime = preprocessing.LabelEncoder()\n",
    "#     crime = le_crime.fit_transform(train_df_new.Category)\n",
    "#     train_df_new['dummy_Category'] = crime\n",
    "\n",
    "    return test_df_new\n",
    "#Calling the feature creation function\n",
    "\n",
    "test_df_new = test_createFeature(test_df)\n",
    "test_df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Exploring with Street Corner Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(884262, 44)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dates', 'DayOfWeek', 'PdDistrict', 'X', 'Y', 'Category',\n",
       "       'month_of_year', 'day_of_month', 'hour_of_day', 'min_of_hour',\n",
       "       'WeekdayWeeekend', 'TimeOfDay', 'Season', 'District_Type', 'Weekday',\n",
       "       'Weekend', 'Afternoon', 'Midnight', 'Morning', 'Night', 'Autumn',\n",
       "       'Spring', 'Summer', 'Winter', 'BAYVIEW', 'CENTRAL', 'INGLESIDE',\n",
       "       'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL',\n",
       "       'TENDERLOIN', 'Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday',\n",
       "       'Tuesday', 'Wednesday', 'Corner', 'Other', 'Street', 'dummy_Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Dates', 'DayOfWeek', 'PdDistrict', 'X', 'Y', 'month_of_year',\n",
       "       'day_of_month', 'hour_of_day', 'min_of_hour', 'WeekdayWeeekend',\n",
       "       'TimeOfDay', 'Season', 'District_Type', 'Weekday', 'Weekend',\n",
       "       'Afternoon', 'Midnight', 'Morning', 'Night', 'Autumn', 'Spring',\n",
       "       'Summer', 'Winter', 'BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION',\n",
       "       'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN',\n",
       "       'Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday',\n",
       "       'Wednesday', 'Corner', 'Other', 'Street'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_new.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Inclusion/Exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lat/Long\n",
    "X_feature = (False, 'X')\n",
    "Y_feature = (False, 'Y')\n",
    "\n",
    "# Time\n",
    "Month_feature = (False, 'month_of_year')\n",
    "Day_feature = (True, 'day_of_month')\n",
    "Hour_feature = (True, 'hour_of_day')\n",
    "Min_feature = (True, 'min_of_hour')\n",
    "\n",
    "# Day of Week\n",
    "Friday_feature = (True, 'Friday') \n",
    "Monday_feature = (True, 'Monday')\n",
    "Saturday_feature = (True, 'Saturday')\n",
    "Sunday_feature = (True, 'Sunday')\n",
    "Thursday_feature = (True, 'Thursday')\n",
    "Tuesday_feature = (True, 'Tuesday')\n",
    "Wednesday_feature = (True, 'Wednesday')\n",
    "\n",
    "#Weekday/Weekend\n",
    "Weekday_feature = (False, 'Weekday') \n",
    "Weekend_feature = (False, 'Weekend') \n",
    "\n",
    "#Season \n",
    "Autumn_feature = (False, 'Autumn') \n",
    "Spring_feature = (False, 'Spring') \n",
    "Summer_feature = (False, 'Summer') \n",
    "Winter_feature = (False, 'Winter') \n",
    "\n",
    "#Time of Day\n",
    "Midnight_feature = (True, 'Midnight') \n",
    "Morning_feature = (True, 'Morning') \n",
    "Afternoon_feature = (True, 'Afternoon') \n",
    "Night_feature = (True, 'Night') \n",
    "\n",
    "# District\n",
    "BAYV_feature = (True, 'BAYVIEW')\n",
    "CENT_feature = (True, 'CENTRAL')\n",
    "INGL_feature = (True, 'INGLESIDE')\n",
    "MISS_feature = (True, 'MISSION')\n",
    "NORT_feature = (True, 'NORTHERN')\n",
    "PARK_feature = (True, 'PARK')\n",
    "RICH_feature = (True, 'RICHMOND')\n",
    "SOUT_feature = (True, 'SOUTHERN')\n",
    "TARA_feature = (True, 'TARAVAL')\n",
    "TEND_feature = (True, 'TENDERLOIN')\n",
    "\n",
    "# # Crime Type\n",
    "# Blue_feature = (False, 'Blue')\n",
    "# White_feature = (False, 'White')\n",
    "# Other_feature = (False, 'Other')\n",
    "\n",
    "# District Type\n",
    "Corner_feature = (False, 'Corner')\n",
    "Street_feature = (False, 'Street')\n",
    "District_Other_feature = (False, 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = [\n",
    "                X_feature, Y_feature,\n",
    "                Month_feature, Day_feature, Hour_feature, Min_feature,\n",
    "                Monday_feature, Tuesday_feature, Wednesday_feature, Thursday_feature, Friday_feature, \n",
    "                Saturday_feature, Sunday_feature,\n",
    "                Weekday_feature, Weekend_feature, \n",
    "                Autumn_feature, Spring_feature, Summer_feature, Winter_feature,\n",
    "                Midnight_feature, Morning_feature, Afternoon_feature, Night_feature, \n",
    "                BAYV_feature, CENT_feature, INGL_feature, MISS_feature, NORT_feature, PARK_feature, \n",
    "                RICH_feature, SOUT_feature, TARA_feature, TEND_feature,\n",
    "#                 Blue_feature, White_feature, Other_feature, \n",
    "                Corner_feature, Street_feature, District_Other_feature\n",
    "               ]\n",
    "features = [str(x[1]) for x in feature_list if x[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "# X = train_df_new[features]\n",
    "# y = train_df_new['dummy_Category'].values\n",
    "\n",
    "# sss = StratifiedShuffleSplit(y, 2, test_size=0.5, random_state=0)\n",
    "\n",
    "# # for train_index, test_index in sss:\n",
    "# #     X_train, X_test = X[train_index], X[test_index]\n",
    "# #     y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainding and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training, validation = train_test_split(train_df_new, train_size=.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# x_train, x_test, y_train, y_test = cross_validation.train_test_split(\n",
    "#     train_df_new[features], train_df_new['dummy_Category'], test_size=0.2, random_state=0)\n",
    "\n",
    "# rf = RandomForestRegressor()\n",
    "# rf.fit(x_train, y_train)\n",
    "# rf.score(x_test, y_test) \n",
    "\n",
    "\n",
    "# # predicted = np.array(rf.predict_proba(validation[features]))\n",
    "# # log_loss(validation['dummy_Category'], predicted) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5607826330505916"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression for comparison\n",
    "model = LogisticRegression(C=.1)\n",
    "model.fit(training[features], training['dummy_Category'])\n",
    "predicted = np.array(model.predict_proba(validation[features]))\n",
    "log_loss(validation['dummy_Category'], predicted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.150, 0.125, 0.1, .075, .05] }\n",
    "\n",
    "param_scores = ['precision', 'recall']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haven't got the gridsearch on logistic regression working yet (possibly need to use less than full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.227 (+/-0.015) for {'C': 0.15}\n",
      "0.226 (+/-0.014) for {'C': 0.125}\n",
      "0.227 (+/-0.015) for {'C': 0.1}\n",
      "0.227 (+/-0.013) for {'C': 0.075}\n",
      "0.227 (+/-0.009) for {'C': 0.05}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlo_liquido/anaconda/lib/python3.4/site-packages/sklearn/cross_validation.py:417: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found arrays with inconsistent numbers of samples: [4000 6000]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-ce2de3aa0881>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dummy_Category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carlo_liquido/anaconda/lib/python3.4/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits)\u001b[0m\n\u001b[1;32m   1248\u001b[0m                                                   \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m                                                   \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m                                                   sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carlo_liquido/anaconda/lib/python3.4/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'binary'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carlo_liquido/anaconda/lib/python3.4/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carlo_liquido/anaconda/lib/python3.4/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         raise ValueError(\"Found arrays with inconsistent numbers of samples: \"\n\u001b[0;32m--> 174\u001b[0;31m                          \"%s\" % str(uniques))\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found arrays with inconsistent numbers of samples: [4000 6000]"
     ]
    }
   ],
   "source": [
    "for score in param_scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(LogisticRegression(penalty='l2'), param_grid)\n",
    "    clf.fit(training[features], training['dummy_Category'])\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    for params, mean_score, scores in clf.grid_scores_:\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean_score, scores.std() * 2, params))\n",
    "    print()\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = validation['dummy_Category'], clf.predict(training[features])\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training, validation = train_test_split(train_df_new, train_size=.60)\n",
    "model = BernoulliNB()\n",
    "model.fit(training[features], training['dummy_Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = np.array(model.predict_proba(validation[features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351220,)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation['dummy_Category'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5491475085908735"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(validation['dummy_Category'], predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** FOR SUBMISSION **\n",
    "\n",
    "** need to train on full trainig set and use the reformatted test data to make prediction **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(884262, 41)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_new = test_df_new.ix[:,1:len(test_df_new)]\n",
    "test_df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training, validation = train_test_split(train_df_new, train_size=.60)\n",
    "model = BernoulliNB()\n",
    "model.fit(train_df_new[features], train_df_new['dummy_Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = np.array(model.predict_proba(test_df_new[features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ex_submission = pd.read_csv(\"kaggle_data/sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result=pd.DataFrame(predicted, columns=ex_submission.columns[1:len(ex_submission)])\n",
    "# result.to_csv('testResult.csv', index = True, index_label = 'Id' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.5881297183958729"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=50, weights='uniform')\n",
    "knn.fit(training[features], training['dummy_Category']) \n",
    "knn_predicted = np.array(knn.predict_proba(validation[features]))\n",
    "log_loss(validation['dummy_Category'], knn_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD STUFF THAT STILL MAY BE OF USE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bernoulli_model = BernoulliNB()\n",
    "Bernoulli_model.fit(x_train, y_train)\n",
    "# predicted = Bernoulli_model.predict_proba(test_data[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21959455611867207"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bernoulli_model.score(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3551620366218122"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training, validation = train_test_split(train_df_new, train_size=.60)\n",
    "model = BernoulliNB()\n",
    "model.fit(training[features], training['dummy_Category'])\n",
    "predicted = np.array(model.predict_proba(validation[features]))\n",
    "log_loss(validation['dummy_Category'], predicted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found arrays with inconsistent numbers of samples: [351220 884262]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-499-7c297380aaf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dummy_Category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dummy_Category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/carlo_liquido/anaconda/lib/python3.4/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m     \u001b[0;31m# Check if dimensions are consistent.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1422\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m     \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carlo_liquido/anaconda/lib/python3.4/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         raise ValueError(\"Found arrays with inconsistent numbers of samples: \"\n\u001b[0;32m--> 174\u001b[0;31m                          \"%s\" % str(uniques))\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found arrays with inconsistent numbers of samples: [351220 884262]"
     ]
    }
   ],
   "source": [
    "training, validation = train_test_split(train_df_new, train_size=.60)\n",
    "model = BernoulliNB()\n",
    "model.fit(training[features], training['dummy_Category'])\n",
    "predicted = np.array(model.predict_proba(test_df_new[features]))\n",
    "log_loss(validation['dummy_Category'], predicted)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result=pd.DataFrame(predicted, columns=ex_submission.columns[1:len(ex_submission)])\n",
    "# result.to_csv('testResult.csv', index = True, index_label = 'Id' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "884262"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22071351289789876"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(validation[features], validation['dummy_Category']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) svm with single fold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 25) (2000, 25)\n",
      "(8000,) (2000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "822262    16\n",
       "751738    35\n",
       "590781     4\n",
       "128821    35\n",
       "875134    31\n",
       "Name: dummy_Category, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.246"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN - gives lowest error; does well with tons of data; ratio does not go to infiniti; data, ratio, (30 max)\n",
    "# extra features on day: holiday; weekend; weekday; time of year; but do exploratory analyssi to find best features\n",
    "# randomforest and decision tree will tell you the importance of feature\n",
    "# 2D kernel density estimation\n",
    "\n",
    "svc_model = svm.SVC(kernel = 'rbf', C=20, gamma=.0075).fit(x_train, y_train)\n",
    "\n",
    "svc_model.score(x_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) svm with crossfolds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 25) (8000,)\n",
      "(2000, 25) (2000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X', 'Y', 'hour_of_day', 'min_of_hour', 'Monday', 'Tuesday',\n",
       "       'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday', 'Autumn',\n",
       "       'Spring', 'Summer', 'Winter', 'BAYVIEW', 'CENTRAL', 'INGLESIDE',\n",
       "       'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL',\n",
       "       'TENDERLOIN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 25)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_df_new[features].shape)\n",
    "print(train_df_new['dummy_Category'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlo_liquido/anaconda/lib/python3.4/site-packages/sklearn/cross_validation.py:417: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.24182359,  0.24327019,  0.23611806,  0.2345555 ,  0.25830816])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_2 = svm.SVC(kernel = 'rbf', C=50, gamma=.001)\n",
    "scores = cross_validation.cross_val_score(\n",
    "    svm_2, train_df_new[features], train_df_new['dummy_Category'], cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM_tuned_parameters = [{'kernel': ['rbf'],\n",
    "                     'gamma': [.0075, .005, .001, .00075], 'C': [20, 30, 40, 50, 60, 70]}\n",
    "                   ]\n",
    "\n",
    "SVM_scores = ['precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(SVM_tuned_parameters)\n",
    "print(SVM_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for score in SVM_scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(svm.SVC(C=1), SVM_tuned_parameters, cv=5,\n",
    "                       scoring='%s_weighted' % score)\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    for params, mean_score, scores in clf.grid_scores_:\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean_score, scores.std() * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(x_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(\n",
    "    train_df_new[features], train_df_new['dummy_Category'], test_size=0.2, random_state=0)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=56, weights='uniform')\n",
    "knn.fit(x_train, y_train) \n",
    "knn.score(x_test, y_test) \n",
    "\n",
    "# KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "#            metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "#            weights='uniform')\n",
    "\n",
    "# knn.predict(x_test)\n",
    "# array([1, 2, 1, 0, 0, 0, 2, 1, 2, 0])\n",
    "# y_test\n",
    "# array([1, 1, 1, 0, 0, 0, 2, 1, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNN_tuned_parameters = [{'n_neighbors': [20, 25, 30, 35, 40, 45]}\n",
    "                   ]\n",
    "\n",
    "KNN_scores = ['precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(KNN_tuned_parameters)\n",
    "print(KNN_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for score in KNN_scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(knn, KNN_tuned_parameters, cv=5,\n",
    "                       scoring='%s_weighted' % score)\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    for params, mean_score, scores in clf.grid_scores_:\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean_score, scores.std() * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(x_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_neighbors, weights=weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
