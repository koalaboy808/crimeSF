{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# defaultcit\n",
    "from collections import defaultdict\n",
    "\n",
    "# plot with folium\n",
    "import folium\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# parsing time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# plotting with matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "# plotting with pylab\n",
    "import pylab as P\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "import time\n",
    "import json\n",
    "\n",
    "# change prediction categories into labels\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_validation \n",
    "from sklearn import svm\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Training/Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** subset to only the fields we need and used in submission (Dates, DayOfWeek, PdDistrict, Address, X, Y, Category) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "# train_df = train_df.sample(n = 10000, random_state = 666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>WARRANTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-13 23:33:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>VANNESS AV / GREENWICH ST</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800414</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>1500 Block of LOMBARD ST</td>\n",
       "      <td>-122.426995</td>\n",
       "      <td>37.800873</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>PARK</td>\n",
       "      <td>100 Block of BRODERICK ST</td>\n",
       "      <td>-122.438738</td>\n",
       "      <td>37.771541</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dates  DayOfWeek PdDistrict                    Address  \\\n",
       "0  2015-05-13 23:53:00  Wednesday   NORTHERN         OAK ST / LAGUNA ST   \n",
       "1  2015-05-13 23:53:00  Wednesday   NORTHERN         OAK ST / LAGUNA ST   \n",
       "2  2015-05-13 23:33:00  Wednesday   NORTHERN  VANNESS AV / GREENWICH ST   \n",
       "3  2015-05-13 23:30:00  Wednesday   NORTHERN   1500 Block of LOMBARD ST   \n",
       "4  2015-05-13 23:30:00  Wednesday       PARK  100 Block of BRODERICK ST   \n",
       "\n",
       "            X          Y        Category  \n",
       "0 -122.425892  37.774599        WARRANTS  \n",
       "1 -122.425892  37.774599  OTHER OFFENSES  \n",
       "2 -122.424363  37.800414  OTHER OFFENSES  \n",
       "3 -122.426995  37.800873   LARCENY/THEFT  \n",
       "4 -122.438738  37.771541   LARCENY/THEFT  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(train_df)\n",
    "test_df = pd.DataFrame(test_df)\n",
    "# train_df = train_df.reset_index(drop=True)\n",
    "train_df = train_df[['Dates','DayOfWeek','PdDistrict','Address','X','Y','Category']]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dates</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-10 23:59:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>2000 Block of THOMAS AV</td>\n",
       "      <td>-122.399588</td>\n",
       "      <td>37.735051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-10 23:51:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>3RD ST / REVERE AV</td>\n",
       "      <td>-122.391523</td>\n",
       "      <td>37.732432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-10 23:50:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>2000 Block of GOUGH ST</td>\n",
       "      <td>-122.426002</td>\n",
       "      <td>37.792212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-05-10 23:45:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>4700 Block of MISSION ST</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-05-10 23:45:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>4700 Block of MISSION ST</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                Dates DayOfWeek PdDistrict                   Address  \\\n",
       "0   0  2015-05-10 23:59:00    Sunday    BAYVIEW   2000 Block of THOMAS AV   \n",
       "1   1  2015-05-10 23:51:00    Sunday    BAYVIEW        3RD ST / REVERE AV   \n",
       "2   2  2015-05-10 23:50:00    Sunday   NORTHERN    2000 Block of GOUGH ST   \n",
       "3   3  2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n",
       "4   4  2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n",
       "\n",
       "            X          Y  \n",
       "0 -122.399588  37.735051  \n",
       "1 -122.391523  37.732432  \n",
       "2 -122.426002  37.792212  \n",
       "3 -122.437394  37.721412  \n",
       "4 -122.437394  37.721412  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878049, 7)\n",
      "(884262, 7)\n"
     ]
    }
   ],
   "source": [
    "#Look at the shape\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** create feature for training data and also for test data **\n",
    "\n",
    "** difference btw train/test is that training has category data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check\n",
      "(878049, 14)\n",
      "(878049, 2)\n",
      "(878049, 4)\n",
      "(878049, 4)\n",
      "(878049, 10)\n",
      "(878049, 7)\n",
      "(878049, 3)\n",
      "(878049, 44)\n",
      "Make sure the total adds up to the last number\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Category</th>\n",
       "      <th>month_of_year</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>min_of_hour</th>\n",
       "      <th>...</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Corner</th>\n",
       "      <th>Other</th>\n",
       "      <th>Street</th>\n",
       "      <th>dummy_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-13 23:33:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800414</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>-122.426995</td>\n",
       "      <td>37.800873</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>PARK</td>\n",
       "      <td>-122.438738</td>\n",
       "      <td>37.771541</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dates  DayOfWeek PdDistrict           X          Y  \\\n",
       "0  2015-05-13 23:53:00  Wednesday   NORTHERN -122.425892  37.774599   \n",
       "1  2015-05-13 23:53:00  Wednesday   NORTHERN -122.425892  37.774599   \n",
       "2  2015-05-13 23:33:00  Wednesday   NORTHERN -122.424363  37.800414   \n",
       "3  2015-05-13 23:30:00  Wednesday   NORTHERN -122.426995  37.800873   \n",
       "4  2015-05-13 23:30:00  Wednesday       PARK -122.438738  37.771541   \n",
       "\n",
       "         Category  month_of_year  day_of_month  hour_of_day  min_of_hour  \\\n",
       "0        WARRANTS              5            13           23           53   \n",
       "1  OTHER OFFENSES              5            13           23           53   \n",
       "2  OTHER OFFENSES              5            13           23           33   \n",
       "3   LARCENY/THEFT              5            13           23           30   \n",
       "4   LARCENY/THEFT              5            13           23           30   \n",
       "\n",
       "        ...       Monday Saturday Sunday Thursday  Tuesday  Wednesday  Corner  \\\n",
       "0       ...            0        0      0        0        0          1       1   \n",
       "1       ...            0        0      0        0        0          1       1   \n",
       "2       ...            0        0      0        0        0          1       1   \n",
       "3       ...            0        0      0        0        0          1       1   \n",
       "4       ...            0        0      0        0        0          1       0   \n",
       "\n",
       "   Other  Street  dummy_Category  \n",
       "0      0       0              37  \n",
       "1      0       0              21  \n",
       "2      0       0              21  \n",
       "3      0       0              16  \n",
       "4      1       0              16  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def createFeature(train_df):\n",
    "    #Getting Month of Year, Day of Month, Hour of Day, and Minute of Hour\n",
    "    month_of_year = []\n",
    "    day_of_month =[]\n",
    "    hour_of_day =[]\n",
    "    min_of_hour =[]\n",
    "    for i in range(len(train_df.Dates.values)):\n",
    "        moy = datetime.strptime(train_df.Dates.values[i], \"%Y-%m-%d %H:%M:%S\").month\n",
    "        dom = datetime.strptime(train_df.Dates.values[i], \"%Y-%m-%d %H:%M:%S\").day\n",
    "        hod = datetime.strptime(train_df.Dates.values[i], \"%Y-%m-%d %H:%M:%S\").hour\n",
    "        moh = datetime.strptime(train_df.Dates.values[i], \"%Y-%m-%d %H:%M:%S\").minute\n",
    "        month_of_year.append(moy)\n",
    "        day_of_month.append(dom)\n",
    "        hour_of_day.append(hod)\n",
    "        min_of_hour.append(moh)\n",
    "    train_df['month_of_year'] = month_of_year #Month of the Year feature added\n",
    "    train_df['day_of_month'] = day_of_month # Day of Month feature added\n",
    "    train_df['hour_of_day'] = hour_of_day # Hour of Day feature added\n",
    "    train_df['min_of_hour'] = min_of_hour # Minute of Hour Feature added\n",
    "    \n",
    "    #Creating Weeekday/Weekended Feature\n",
    "    train_df['WeekdayWeeekend'] = train_df['DayOfWeek'].map( {'Monday': 'Weekday', 'Tuesday': 'Weekday', \\\n",
    "                                                          'Wednesday': 'Weekday', 'Thursday': 'Weekday', 'Friday': 'Weekend',\\\n",
    "                                                         'Saturday': 'Weekend', 'Sunday': 'Weekday'} ).astype(object)\n",
    "    # Creating Midnight/Morning/Afternoon/Night Column\n",
    "    train_df['TimeOfDay'] = train_df['hour_of_day'].map({0: 'Midnight', 1: 'Midnight', 2:'Midnight', 3:'Midnight', 4:'Morning', \\\n",
    "                                                     5:'Morning', 6:'Morning', 7:'Morning', 8:'Morning', 9:'Morning', \\\n",
    "                                                     10:'Morning', 11:'Morning', 12:'Afternoon', 13:'Afternoon', 14:'Afternoon', \\\n",
    "                                                     15:'Afternoon', 16:'Afternoon', 17:'Afternoon', 18:'Night', 19:'Night', \\\n",
    "                                                     20:'Night', 21:'Night', 22:'Midnight', 23:'Midnight'}).astype(object)\n",
    "    # Creating Season Feature\n",
    "    train_df['Season'] = train_df['month_of_year'].map({1: 'Winter', 2: 'Winter', 3:'Spring', 4:'Spring', 5:'Spring', \\\n",
    "                                                     6:'Spring', 7:'Summer', 8:'Summer', 9:'Summer', 10:'Autumn', \\\n",
    "                                                     11:'Autumn', 12:'Winter'}).astype(object)\n",
    "\n",
    "    \n",
    "    train_df['District_Type'] = train_df['PdDistrict'].map({'PARK': 'Other', 'CENTRAL': 'Other', 'MISSION': 'Corner', 'NORTHERN': 'Corner', \n",
    "                                                              'TENDERLOIN': 'Other', 'INGLESIDE': 'Street', 'TARAVAL': 'Street', \n",
    "                                                              'SOUTHERN': 'Other', 'BAYVIEW': 'Other', 'RICHMOND': 'Other'}).astype(object)\n",
    "\n",
    "        \n",
    "    #Deleting features not needed\n",
    "#     train_df = train_df.drop('Descript', 1)\n",
    "#     train_df = train_df.drop('Resolution', 1)\n",
    "    train_df = train_df.drop('Address', 1)\n",
    "    \n",
    "    #Creating Dummy Variables\n",
    "    WeekdayWeekend_dummies = pd.get_dummies(train_df.WeekdayWeeekend)\n",
    "    TimeOfDay_dummies = pd.get_dummies(train_df.TimeOfDay)\n",
    "    season_dummies = pd.get_dummies(train_df.Season)\n",
    "    district_dummies = pd.get_dummies(train_df.PdDistrict)\n",
    "    week_dummies = pd.get_dummies(train_df.DayOfWeek)\n",
    "#     type_dummies = pd.get_dummies(train_df.Crime_Type)\n",
    "    corner_dummies = pd.get_dummies(train_df.District_Type)\n",
    "    \n",
    "    train_df_new = pd.concat([train_df, WeekdayWeekend_dummies, TimeOfDay_dummies, season_dummies, district_dummies, week_dummies, corner_dummies], axis=1, join_axes=[train_df.index])\n",
    "    print('Sanity Check')\n",
    "    print(train_df.shape)\n",
    "    print(WeekdayWeekend_dummies.shape)\n",
    "    print(TimeOfDay_dummies.shape)\n",
    "    print(season_dummies.shape)\n",
    "    print(district_dummies.shape)\n",
    "    print(week_dummies.shape)\n",
    "#     print(type_dummies.shape)\n",
    "    print(corner_dummies.shape)\n",
    "    print(train_df_new.shape)\n",
    "    print('Make sure the total adds up to the last number')\n",
    "    \n",
    "    le_crime = preprocessing.LabelEncoder()\n",
    "    crime = le_crime.fit_transform(train_df_new.Category)\n",
    "    train_df_new['dummy_Category'] = crime\n",
    "\n",
    "    return train_df_new\n",
    "#Calling the feature creation function\n",
    "train_df_new = createFeature(train_df)\n",
    "train_df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** create feature for test data **\n",
    "\n",
    "*difference is that Cateogry doesn't exist in test data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check\n",
      "(884262, 14)\n",
      "(884262, 2)\n",
      "(884262, 4)\n",
      "(884262, 4)\n",
      "(884262, 10)\n",
      "(884262, 7)\n",
      "(884262, 3)\n",
      "(884262, 44)\n",
      "Make sure the total adds up to the last number\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dates</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>month_of_year</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>min_of_hour</th>\n",
       "      <th>...</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Corner</th>\n",
       "      <th>Other</th>\n",
       "      <th>Street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-10 23:59:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>-122.399588</td>\n",
       "      <td>37.735051</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-10 23:51:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>-122.391523</td>\n",
       "      <td>37.732432</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-10 23:50:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>-122.426002</td>\n",
       "      <td>37.792212</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-05-10 23:45:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-05-10 23:45:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                Dates DayOfWeek PdDistrict           X          Y  \\\n",
       "0   0  2015-05-10 23:59:00    Sunday    BAYVIEW -122.399588  37.735051   \n",
       "1   1  2015-05-10 23:51:00    Sunday    BAYVIEW -122.391523  37.732432   \n",
       "2   2  2015-05-10 23:50:00    Sunday   NORTHERN -122.426002  37.792212   \n",
       "3   3  2015-05-10 23:45:00    Sunday  INGLESIDE -122.437394  37.721412   \n",
       "4   4  2015-05-10 23:45:00    Sunday  INGLESIDE -122.437394  37.721412   \n",
       "\n",
       "   month_of_year  day_of_month  hour_of_day  min_of_hour   ...   Friday  \\\n",
       "0              5            10           23           59   ...        0   \n",
       "1              5            10           23           51   ...        0   \n",
       "2              5            10           23           50   ...        0   \n",
       "3              5            10           23           45   ...        0   \n",
       "4              5            10           23           45   ...        0   \n",
       "\n",
       "  Monday Saturday Sunday  Thursday  Tuesday  Wednesday  Corner  Other  Street  \n",
       "0      0        0      1         0        0          0       0      1       0  \n",
       "1      0        0      1         0        0          0       0      1       0  \n",
       "2      0        0      1         0        0          0       1      0       0  \n",
       "3      0        0      1         0        0          0       0      0       1  \n",
       "4      0        0      1         0        0          0       0      0       1  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_createFeature(test_df):\n",
    "    #Getting Month of Year, Day of Month, Hour of Day, and Minute of Hour\n",
    "    month_of_year = []\n",
    "    day_of_month =[]\n",
    "    hour_of_day =[]\n",
    "    min_of_hour =[]\n",
    "    for i in range(len(test_df.Dates.values)):\n",
    "        moy = datetime.strptime(test_df.Dates.values[i], \"%Y-%m-%d %H:%M:%S\").month\n",
    "        dom = datetime.strptime(test_df.Dates.values[i], \"%Y-%m-%d %H:%M:%S\").day\n",
    "        hod = datetime.strptime(test_df.Dates.values[i], \"%Y-%m-%d %H:%M:%S\").hour\n",
    "        moh = datetime.strptime(test_df.Dates.values[i], \"%Y-%m-%d %H:%M:%S\").minute\n",
    "        month_of_year.append(moy)\n",
    "        day_of_month.append(dom)\n",
    "        hour_of_day.append(hod)\n",
    "        min_of_hour.append(moh)\n",
    "    test_df['month_of_year'] = month_of_year #Month of the Year feature added\n",
    "    test_df['day_of_month'] = day_of_month # Day of Month feature added\n",
    "    test_df['hour_of_day'] = hour_of_day # Hour of Day feature added\n",
    "    test_df['min_of_hour'] = min_of_hour # Minute of Hour Feature added\n",
    "    \n",
    "    #Creating Weeekday/Weekended Feature\n",
    "    test_df['WeekdayWeeekend'] = test_df['DayOfWeek'].map( {'Monday': 'Weekday', 'Tuesday': 'Weekday', \\\n",
    "                                                          'Wednesday': 'Weekend', 'Thursday': 'Weekend', 'Friday': 'Weekend',\\\n",
    "                                                         'Saturday': 'Weekend', 'Sunday': 'Weekday'} ).astype(object)\n",
    "    # Creating Midnight/Morning/Afternoon/Night Column\n",
    "    test_df['TimeOfDay'] = test_df['hour_of_day'].map({0: 'Night', 1: 'Midnight', 2:'Midnight', 3:'Midnight', 4:'Midnight', \\\n",
    "                                                     5:'Midnight', 6:'Midnight', 7:'Midnight', 8:'Morning', 9:'Morning', \\\n",
    "                                                     10:'Morning', 11:'Morning', 12:'Afternoon', 13:'Afternoon', 14:'Afternoon', \\\n",
    "                                                     15:'Afternoon', 16:'Afternoon', 17:'Afternoon', 18:'Afternoon', 19:'Afternoon', \\\n",
    "                                                     20:'Night', 21:'Night', 22:'Night', 23:'Night'}).astype(object)\n",
    "    # Creating Season Feature\n",
    "    test_df['Season'] = test_df['month_of_year'].map({1: 'Winter', 2: 'Winter', 3:'Spring', 4:'Spring', 5:'Spring', \\\n",
    "                                                     6:'Spring', 7:'Summer', 8:'Summer', 9:'Summer', 10:'Autumn', \\\n",
    "                                                     11:'Autumn', 12:'Winter'}).astype(object)\n",
    "\n",
    "    \n",
    "    \n",
    "    test_df['District_Type'] = test_df['PdDistrict'].map({'PARK': 'Other', 'CENTRAL': 'Other', 'MISSION': 'Corner', 'NORTHERN': 'Corner', \n",
    "                                                              'TENDERLOIN': 'Other', 'INGLESIDE': 'Street', 'TARAVAL': 'Street', \n",
    "                                                              'SOUTHERN': 'Other', 'BAYVIEW': 'Other', 'RICHMOND': 'Other'}).astype(object)\n",
    "\n",
    "        \n",
    "    #Deleting features not needed\n",
    "#     test_df = test_df.drop('Descript', 1)\n",
    "#     test_df = test_df.drop('Resolution', 1)\n",
    "    test_df = test_df.drop('Address', 1)\n",
    "    \n",
    "    #Creating Dummy Variables\n",
    "    WeekdayWeekend_dummies = pd.get_dummies(test_df.WeekdayWeeekend)\n",
    "    TimeOfDay_dummies = pd.get_dummies(test_df.TimeOfDay)\n",
    "    season_dummies = pd.get_dummies(test_df.Season)\n",
    "    district_dummies = pd.get_dummies(test_df.PdDistrict)\n",
    "    week_dummies = pd.get_dummies(test_df.DayOfWeek)\n",
    "#     type_dummies = pd.get_dummies(test_df.Crime_Type)\n",
    "    corner_dummies = pd.get_dummies(test_df.District_Type)\n",
    "    \n",
    "    test_df_new = pd.concat([test_df, WeekdayWeekend_dummies, TimeOfDay_dummies, season_dummies, district_dummies, week_dummies, corner_dummies], axis=1, join_axes=[test_df.index])\n",
    "    print('Sanity Check')\n",
    "    print(test_df.shape)\n",
    "    print(WeekdayWeekend_dummies.shape)\n",
    "    print(TimeOfDay_dummies.shape)\n",
    "    print(season_dummies.shape)\n",
    "    print(district_dummies.shape)\n",
    "    print(week_dummies.shape)\n",
    "#     print(type_dummies.shape)\n",
    "    print(corner_dummies.shape)\n",
    "    print(test_df_new.shape)\n",
    "    print('Make sure the total adds up to the last number')\n",
    "    \n",
    "#     le_crime = preprocessing.LabelEncoder()\n",
    "#     crime = le_crime.fit_transform(train_df_new.Category)\n",
    "#     train_df_new['dummy_Category'] = crime\n",
    "\n",
    "    return test_df_new\n",
    "#Calling the feature creation function\n",
    "\n",
    "test_df_new = test_createFeature(test_df)\n",
    "test_df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Exploring with Street Corner Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(884262, 44)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dates', 'DayOfWeek', 'PdDistrict', 'X', 'Y', 'Category',\n",
       "       'month_of_year', 'day_of_month', 'hour_of_day', 'min_of_hour',\n",
       "       'WeekdayWeeekend', 'TimeOfDay', 'Season', 'District_Type', 'Weekday',\n",
       "       'Weekend', 'Afternoon', 'Midnight', 'Morning', 'Night', 'Autumn',\n",
       "       'Spring', 'Summer', 'Winter', 'BAYVIEW', 'CENTRAL', 'INGLESIDE',\n",
       "       'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL',\n",
       "       'TENDERLOIN', 'Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday',\n",
       "       'Tuesday', 'Wednesday', 'Corner', 'Other', 'Street', 'dummy_Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Dates', 'DayOfWeek', 'PdDistrict', 'X', 'Y', 'month_of_year',\n",
       "       'day_of_month', 'hour_of_day', 'min_of_hour', 'WeekdayWeeekend',\n",
       "       'TimeOfDay', 'Season', 'District_Type', 'Weekday', 'Weekend',\n",
       "       'Afternoon', 'Midnight', 'Morning', 'Night', 'Autumn', 'Spring',\n",
       "       'Summer', 'Winter', 'BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION',\n",
       "       'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN',\n",
       "       'Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday',\n",
       "       'Wednesday', 'Corner', 'Other', 'Street'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_new.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Inclusion/Exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Lat/Long\n",
    "# X_feature = (False, 'X')\n",
    "# Y_feature = (False, 'Y')\n",
    "\n",
    "# # Time\n",
    "# Month_feature = (False, 'month_of_year')\n",
    "# Day_feature = (True, 'day_of_month')\n",
    "# Hour_feature = (True, 'hour_of_day')\n",
    "# Min_feature = (True, 'min_of_hour')\n",
    "\n",
    "# # Day of Week\n",
    "# Friday_feature = (True, 'Friday') \n",
    "# Monday_feature = (True, 'Monday')\n",
    "# Saturday_feature = (True, 'Saturday')\n",
    "# Sunday_feature = (True, 'Sunday')\n",
    "# Thursday_feature = (True, 'Thursday')\n",
    "# Tuesday_feature = (True, 'Tuesday')\n",
    "# Wednesday_feature = (True, 'Wednesday')\n",
    "\n",
    "# #Weekday/Weekend\n",
    "# Weekday_feature = (False, 'Weekday') \n",
    "# Weekend_feature = (False, 'Weekend') \n",
    "\n",
    "# #Season \n",
    "# Autumn_feature = (False, 'Autumn') \n",
    "# Spring_feature = (False, 'Spring') \n",
    "# Summer_feature = (False, 'Summer') \n",
    "# Winter_feature = (False, 'Winter') \n",
    "\n",
    "# #Time of Day\n",
    "# Midnight_feature = (True, 'Midnight') \n",
    "# Morning_feature = (True, 'Morning') \n",
    "# Afternoon_feature = (True, 'Afternoon') \n",
    "# Night_feature = (True, 'Night') \n",
    "\n",
    "# # District\n",
    "# BAYV_feature = (True, 'BAYVIEW')\n",
    "# CENT_feature = (True, 'CENTRAL')\n",
    "# INGL_feature = (True, 'INGLESIDE')\n",
    "# MISS_feature = (True, 'MISSION')\n",
    "# NORT_feature = (True, 'NORTHERN')\n",
    "# PARK_feature = (True, 'PARK')\n",
    "# RICH_feature = (True, 'RICHMOND')\n",
    "# SOUT_feature = (True, 'SOUTHERN')\n",
    "# TARA_feature = (True, 'TARAVAL')\n",
    "# TEND_feature = (True, 'TENDERLOIN')\n",
    "\n",
    "# # # Crime Type\n",
    "# # Blue_feature = (False, 'Blue')\n",
    "# # White_feature = (False, 'White')\n",
    "# # Other_feature = (False, 'Other')\n",
    "\n",
    "# # District Type\n",
    "# Corner_feature = (False, 'Corner')\n",
    "# Street_feature = (False, 'Street')\n",
    "# District_Other_feature = (False, 'Other')\n",
    "\n",
    "# Lat/Long\n",
    "X_feature = (True, 'X')\n",
    "Y_feature = (True, 'Y')\n",
    "\n",
    "# Time\n",
    "Month_feature = (True, 'month_of_year')\n",
    "Day_feature = (True, 'day_of_month')\n",
    "Hour_feature = (True, 'hour_of_day')\n",
    "Min_feature = (True, 'min_of_hour')\n",
    "\n",
    "# Day of Week\n",
    "Friday_feature = (True, 'Friday') \n",
    "Monday_feature = (True, 'Monday')\n",
    "Saturday_feature = (True, 'Saturday')\n",
    "Sunday_feature = (True, 'Sunday')\n",
    "Thursday_feature = (True, 'Thursday')\n",
    "Tuesday_feature = (True, 'Tuesday')\n",
    "Wednesday_feature = (True, 'Wednesday')\n",
    "\n",
    "#Weekday/Weekend\n",
    "Weekday_feature = (True, 'Weekday') \n",
    "Weekend_feature = (True, 'Weekend') \n",
    "\n",
    "#Season \n",
    "Autumn_feature = (True, 'Autumn') \n",
    "Spring_feature = (True, 'Spring') \n",
    "Summer_feature = (True, 'Summer') \n",
    "Winter_feature = (True, 'Winter') \n",
    "\n",
    "#Time of Day\n",
    "Midnight_feature = (True, 'Midnight') \n",
    "Morning_feature = (True, 'Morning') \n",
    "Afternoon_feature = (True, 'Afternoon') \n",
    "Night_feature = (True, 'Night') \n",
    "\n",
    "# District\n",
    "BAYV_feature = (True, 'BAYVIEW')\n",
    "CENT_feature = (True, 'CENTRAL')\n",
    "INGL_feature = (True, 'INGLESIDE')\n",
    "MISS_feature = (True, 'MISSION')\n",
    "NORT_feature = (True, 'NORTHERN')\n",
    "PARK_feature = (True, 'PARK')\n",
    "RICH_feature = (True, 'RICHMOND')\n",
    "SOUT_feature = (True, 'SOUTHERN')\n",
    "TARA_feature = (True, 'TARAVAL')\n",
    "TEND_feature = (True, 'TENDERLOIN')\n",
    "\n",
    "# # Crime Type\n",
    "# Blue_feature = (False, 'Blue')\n",
    "# White_feature = (False, 'White')\n",
    "# Other_feature = (False, 'Other')\n",
    "\n",
    "# District Type\n",
    "Corner_feature = (True, 'Corner')\n",
    "Street_feature = (True, 'Street')\n",
    "District_Other_feature = (True, 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = [\n",
    "                X_feature, Y_feature,\n",
    "                Month_feature, Day_feature, Hour_feature, Min_feature,\n",
    "                Monday_feature, Tuesday_feature, Wednesday_feature, Thursday_feature, Friday_feature, \n",
    "                Saturday_feature, Sunday_feature,\n",
    "                Weekday_feature, Weekend_feature, \n",
    "                Autumn_feature, Spring_feature, Summer_feature, Winter_feature,\n",
    "                Midnight_feature, Morning_feature, Afternoon_feature, Night_feature, \n",
    "                BAYV_feature, CENT_feature, INGL_feature, MISS_feature, NORT_feature, PARK_feature, \n",
    "                RICH_feature, SOUT_feature, TARA_feature, TEND_feature,\n",
    "#                 Blue_feature, White_feature, Other_feature, \n",
    "                Corner_feature, Street_feature, District_Other_feature\n",
    "               ]\n",
    "features = [str(x[1]) for x in feature_list if x[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainding and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training, validation = train_test_split(train_df_new, train_size=.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False  True  True  True]\n",
      "[33 28 31 30 32 34 21 27 19 26  4  3 25  2 29 12 14 13 11 10  8  7  9  6 17\n",
      " 23 24 16 22 18 15 20  5  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create a base classifier used to evaluate a subset of attributes\n",
    "model = LogisticRegression()\n",
    "\n",
    "# create the RFE model and select 3 attributes\n",
    "rfe = RFE(model, 3)\n",
    "rfe = rfe.fit(training[features].values, training['dummy_Category'].values)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# # fit an Extra Trees model to the data\n",
    "# model = ExtraTreesClassifier()\n",
    "# model.fit(training[features].values, training['dummy_Category'].values)\n",
    "# # display the relative importance of each attribute\n",
    "# print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# keep_index = list(rfe.support_)\n",
    "keep_index = list(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Friday',\n",
       " 'Saturday',\n",
       " 'Weekday',\n",
       " 'Morning',\n",
       " 'Afternoon',\n",
       " 'Night',\n",
       " 'BAYVIEW',\n",
       " 'TENDERLOIN',\n",
       " 'Corner',\n",
       " 'Street',\n",
       " 'Other']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_features = [features[index] for index, value in enumerate(keep_index) if value < 10]\n",
    "keep_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_features2 = [features[index] for index, value in enumerate(keep_index) if value < 2]\n",
    "keep_features3 = [features[index] for index, value in enumerate(keep_index) if value < 4]\n",
    "keep_features4 = [features[index] for index, value in enumerate(keep_index) if value < 6]\n",
    "keep_features5 = [features[index] for index, value in enumerate(keep_index) if value < 8]\n",
    "keep_features6 = [features[index] for index, value in enumerate(keep_index) if value < 10]\n",
    "keep_features7 = [features[index] for index, value in enumerate(keep_index) if value < 12]\n",
    "keep_features8 = [features[index] for index, value in enumerate(keep_index) if value < 14]\n",
    "keep_features9 = [features[index] for index, value in enumerate(keep_index) if value < 16]\n",
    "keep_features10 = [features[index] for index, value in enumerate(keep_index) if value < 18]\n",
    "keep_features11 = [features[index] for index, value in enumerate(keep_index) if value < 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X, y = training[features].values, training['dummy_Category'].values\n",
    "# print(X.shape,y.shape)\n",
    "# print(type(X),type(y))\n",
    "\n",
    "# X_new = SelectKBest(f_regression, k=2).fit_transform(X, y)\n",
    "# print(X_new.shape)\n",
    "# print(pd.DataFrame(X_new))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pipline \n",
    "** doesn't work.... **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, decomposition, datasets\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training, validation = train_test_split(train_df_new, train_size=.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "pca = decomposition.PCA(whiten=True)\n",
    "pipe = Pipeline(steps=[('pca', pca), ('logistic', logistic)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7.15466275e-01   1.60540595e-01   9.07014375e-02   2.48765679e-02\n",
      "   1.17667812e-03   1.03825915e-03   6.24662867e-04   6.06676192e-04\n",
      "   5.99178204e-04   4.79488401e-04   4.62991309e-04   3.17398254e-04\n",
      "   3.13261213e-04   3.07089689e-04   3.00127624e-04   2.99274267e-04\n",
      "   2.89278258e-04   2.79484728e-04   2.60141645e-04   2.36383463e-04\n",
      "   2.10155131e-04   2.02856039e-04   1.70579287e-04   1.31684106e-04\n",
      "   1.09111077e-04   1.96564312e-07   1.69223945e-07   1.41100843e-31\n",
      "   7.59033970e-33   7.59033970e-33   7.59033970e-33   7.59033970e-33\n",
      "   7.59033970e-33   7.59033970e-33   7.59033970e-33   7.59033970e-33]\n"
     ]
    }
   ],
   "source": [
    "pca.fit_transform(training[features])\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11a0b44e0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQMAAADECAYAAACbS0RzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGAghKkkYCCEACQMhRCUJAyEEAP8fM6LzZ55Laz4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113cb1a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pca.fit(training[features])\n",
    "plt.figure(1, figsize=(4, 3))\n",
    "plt.clf()\n",
    "plt.axes([.2, .2, .7, .7])\n",
    "plt.plot(pca.explained_variance_, linewidth=2)\n",
    "plt.axis('tight')\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('explained_variance_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlo_liquido/anaconda/lib/python3.4/site-packages/sklearn/cross_validation.py:417: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('pca', PCA(copy=True, n_components=None, whiten=True)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0))]),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
       "       param_grid={'logistic__C': array([  1.00000e-04,   1.00000e+00,   1.00000e+04]), 'pca__n_components': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction\n",
    "\n",
    "n_components = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "Cs = np.logspace(-4, 4, 3)\n",
    "\n",
    "#Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "\n",
    "estimator = GridSearchCV(pipe,\n",
    "                         dict(pca__n_components=n_components,\n",
    "                              logistic__C=Cs))\n",
    "estimator.fit(training[features], training['dummy_Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5617459347413405"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimator.score(validation[features], validation['dummy_Category'])\n",
    "predicted = np.array(estimator.predict_proba(validation[features]))\n",
    "log_loss(validation['dummy_Category'], predicted) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just use keep features based on skbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6129125616700111"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression for comparison\n",
    "model = LogisticRegression(C=.1)\n",
    "model.fit(training[keep_features], training['dummy_Category'])\n",
    "predicted = np.array(model.predict_proba(validation[keep_features1]))\n",
    "log_loss(validation['dummy_Category'], predicted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6655445818679446"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training[keep_features2], training['dummy_Category'])\n",
    "predicted = np.array(model.predict_proba(validation[keep_features2]))\n",
    "log_loss(validation['dummy_Category'], predicted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6644519589782734"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training[keep_features3], training['dummy_Category'])\n",
    "predicted = np.array(model.predict_proba(validation[keep_features3]))\n",
    "log_loss(validation['dummy_Category'], predicted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6418390424735612"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training[keep_features4], training['dummy_Category'])\n",
    "predicted = np.array(model.predict_proba(validation[keep_features4]))\n",
    "log_loss(validation['dummy_Category'], predicted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6251225126883804"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training[keep_features5], training['dummy_Category'])\n",
    "predicted = np.array(model.predict_proba(validation[keep_features5]))\n",
    "log_loss(validation['dummy_Category'], predicted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6129125616697424"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training[keep_features6], training['dummy_Category'])\n",
    "predicted = np.array(model.predict_proba(validation[keep_features6]))\n",
    "log_loss(validation['dummy_Category'], predicted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6126947082154568"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training[keep_features7], training['dummy_Category'])\n",
    "predicted = np.array(model.predict_proba(validation[keep_features7]))\n",
    "log_loss(validation['dummy_Category'], predicted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6125926163405153"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training[keep_features8], training['dummy_Category'])\n",
    "predicted = np.array(model.predict_proba(validation[keep_features8]))\n",
    "log_loss(validation['dummy_Category'], predicted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6072294100961075"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training[keep_features9], training['dummy_Category'])\n",
    "predicted = np.array(model.predict_proba(validation[keep_features9]))\n",
    "log_loss(validation['dummy_Category'], predicted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5991616767874071"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training[keep_features10], training['dummy_Category'])\n",
    "predicted = np.array(model.predict_proba(validation[keep_features10]))\n",
    "log_loss(validation['dummy_Category'], predicted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5975554374874879"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training[keep_features11], training['dummy_Category'])\n",
    "predicted = np.array(model.predict_proba(validation[keep_features11]))\n",
    "log_loss(validation['dummy_Category'], predicted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6120055024309714"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training[features], training['dummy_Category'])\n",
    "predicted = np.array(model.predict_proba(validation[features]))\n",
    "log_loss(validation['dummy_Category'], predicted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression.pkl',\n",
       " 'logistic_regression.pkl_01.npy',\n",
       " 'logistic_regression.pkl_02.npy',\n",
       " 'logistic_regression.pkl_03.npy',\n",
       " 'logistic_regression.pkl_04.npy',\n",
       " 'logistic_regression.pkl_05.npy']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.externals import joblib\n",
    "# joblib.dump(model, 'logistic_regression.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# now you can save it to a file\n",
    "with open('logistic_regression.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df_testing = test_df_new.iloc[[1,100,1000,10000,100000]]\n",
    "test_df_testing = test_df_testing[features]\n",
    "# test_df_testing[:10]\n",
    "test_df_testing.to_csv('testing_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.150, 0.125, 0.1, .075, .05] }\n",
    "\n",
    "param_scores = ['precision', 'recall']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haven't got the gridsearch on logistic regression working yet (possibly need to use less than full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for score in param_scores:\n",
    "#     print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "#     print()\n",
    "\n",
    "#     clf = GridSearchCV(LogisticRegression(penalty='l2'), param_grid)\n",
    "#     clf.fit(training[features], training['dummy_Category'])\n",
    "\n",
    "#     print(\"Best parameters set found on development set:\")\n",
    "#     print()\n",
    "#     print(clf.best_params_)\n",
    "#     print()\n",
    "#     print(\"Grid scores on development set:\")\n",
    "#     print()\n",
    "#     for params, mean_score, scores in clf.grid_scores_:\n",
    "#         print(\"%0.3f (+/-%0.03f) for %r\" % (mean_score, scores.std() * 2, params))\n",
    "#     print()\n",
    "#     print(\"Detailed classification report:\")\n",
    "#     print()\n",
    "#     print(\"The model is trained on the full development set.\")\n",
    "#     print(\"The scores are computed on the full evaluation set.\")\n",
    "#     print()\n",
    "#     y_true, y_pred = validation['dummy_Category'], clf.predict(training[features])\n",
    "#     print(classification_report(y_true, y_pred))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training, validation = train_test_split(train_df_new, train_size=.60)\n",
    "model = BernoulliNB()\n",
    "model.fit(training[features], training['dummy_Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = np.array(model.predict_proba(validation[features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351220,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation['dummy_Category'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6120055024309714"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(validation['dummy_Category'], predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** FOR SUBMISSION **\n",
    "\n",
    "** need to train on full trainig set and use the reformatted test data to make prediction **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(884262, 43)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_new = test_df_new.ix[:,1:len(test_df_new)]\n",
    "test_df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training, validation = train_test_split(train_df_new, train_size=.60)\n",
    "model = BernoulliNB()\n",
    "model.fit(train_df_new[features], train_df_new['dummy_Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = np.array(model.predict_proba(test_df_new[features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ex_submission = pd.read_csv(\"kaggle_data/sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result=pd.DataFrame(predicted, columns=ex_submission.columns[1:len(ex_submission)])\n",
    "# result.to_csv('testResult.csv', index = True, index_label = 'Id' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=50, weights='uniform')\n",
    "knn.fit(training[features], training['dummy_Category']) \n",
    "knn_predicted = np.array(knn.predict_proba(validation[features]))\n",
    "log_loss(validation['dummy_Category'], knn_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD STUFF THAT STILL MAY BE OF USE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Bernoulli_model = BernoulliNB()\n",
    "Bernoulli_model.fit(x_train, y_train)\n",
    "# predicted = Bernoulli_model.predict_proba(test_data[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Bernoulli_model.score(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training, validation = train_test_split(train_df_new, train_size=.60)\n",
    "model = BernoulliNB()\n",
    "model.fit(training[features], training['dummy_Category'])\n",
    "predicted = np.array(model.predict_proba(validation[features]))\n",
    "log_loss(validation['dummy_Category'], predicted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training, validation = train_test_split(train_df_new, train_size=.60)\n",
    "model = BernoulliNB()\n",
    "model.fit(training[features], training['dummy_Category'])\n",
    "predicted = np.array(model.predict_proba(test_df_new[features]))\n",
    "log_loss(validation['dummy_Category'], predicted)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result=pd.DataFrame(predicted, columns=ex_submission.columns[1:len(ex_submission)])\n",
    "# result.to_csv('testResult.csv', index = True, index_label = 'Id' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.score(validation[features], validation['dummy_Category']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) svm with single fold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#KNN - gives lowest error; does well with tons of data; ratio does not go to infiniti; data, ratio, (30 max)\n",
    "# extra features on day: holiday; weekend; weekday; time of year; but do exploratory analyssi to find best features\n",
    "# randomforest and decision tree will tell you the importance of feature\n",
    "# 2D kernel density estimation\n",
    "\n",
    "svc_model = svm.SVC(kernel = 'rbf', C=20, gamma=.0075).fit(x_train, y_train)\n",
    "\n",
    "svc_model.score(x_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) svm with crossfolds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train_df_new[features].shape)\n",
    "print(train_df_new['dummy_Category'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_2 = svm.SVC(kernel = 'rbf', C=50, gamma=.001)\n",
    "scores = cross_validation.cross_val_score(\n",
    "    svm_2, train_df_new[features], train_df_new['dummy_Category'], cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM_tuned_parameters = [{'kernel': ['rbf'],\n",
    "                     'gamma': [.0075, .005, .001, .00075], 'C': [20, 30, 40, 50, 60, 70]}\n",
    "                   ]\n",
    "\n",
    "SVM_scores = ['precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(SVM_tuned_parameters)\n",
    "print(SVM_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for score in SVM_scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(svm.SVC(C=1), SVM_tuned_parameters, cv=5,\n",
    "                       scoring='%s_weighted' % score)\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    for params, mean_score, scores in clf.grid_scores_:\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean_score, scores.std() * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(x_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(\n",
    "    train_df_new[features], train_df_new['dummy_Category'], test_size=0.2, random_state=0)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=56, weights='uniform')\n",
    "knn.fit(x_train, y_train) \n",
    "knn.score(x_test, y_test) \n",
    "\n",
    "# KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "#            metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "#            weights='uniform')\n",
    "\n",
    "# knn.predict(x_test)\n",
    "# array([1, 2, 1, 0, 0, 0, 2, 1, 2, 0])\n",
    "# y_test\n",
    "# array([1, 1, 1, 0, 0, 0, 2, 1, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNN_tuned_parameters = [{'n_neighbors': [20, 25, 30, 35, 40, 45]}\n",
    "                   ]\n",
    "\n",
    "KNN_scores = ['precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(KNN_tuned_parameters)\n",
    "print(KNN_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for score in KNN_scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(knn, KNN_tuned_parameters, cv=5,\n",
    "                       scoring='%s_weighted' % score)\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    for params, mean_score, scores in clf.grid_scores_:\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean_score, scores.std() * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(x_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_neighbors, weights=weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
